use crate::block::{Block, BlockHeader, compute_header_hash, compute_merkle_root};
use crate::db::{open_db, put_batch};
use crate::transaction::Transaction;
use crate::utxo::Utxo;
use anyhow::{Result, anyhow};
use bincode::config;
use chrono::Utc;
use hex;
use log;
use once_cell::sync::Lazy;
use primitive_types::U256;
use rocksdb::{DB, WriteBatch};

pub static BINCODE_CONFIG: Lazy<config::Configuration> = Lazy::new(|| config::standard());

/// Blockchain structure (disk-based RocksDB storage)
///
/// This structure manages the blockchain state including:
/// - Block storage and retrieval
/// - Transaction validation and UTXO management
/// - Chain tip tracking
/// - Balance and transaction queries
pub struct Blockchain {
    pub db: DB,
    pub chain_tip: Option<String>, // tip hash hex
    pub difficulty: u32,
    pub block_interval: i64,  // Target block generation interval (seconds)
    pub max_reorg_depth: u64, // Maximum allowed reorganization depth (security)
    pub max_future_block_time: i64, // Maximum seconds a block can be in the future
    pub enable_deep_reorg_alerts: bool, // Alert on deep reorgs (vs hard reject)
}

impl Blockchain {
    const POW_LIMIT_BITS: u32 = 0x1d0fffff; // Easiest allowed target (testnet-like)
    const POW_MIN_BITS: u32 = 0x1900ffff; // Hardest allowed target
    const RETARGET_WINDOW: u64 = 30; // 30 blocks rolling window

    fn compact_to_target(bits: u32) -> U256 {
        let exponent = bits >> 24;
        let mantissa = bits & 0x007f_ffff;
        if mantissa == 0 {
            return U256::zero();
        }

        if exponent <= 3 {
            U256::from(mantissa >> (8 * (3 - exponent)))
        } else {
            U256::from(mantissa) << (8 * (exponent - 3))
        }
    }

    fn target_to_compact(target: U256) -> u32 {
        if target.is_zero() {
            return 0;
        }

        let mut bytes = [0u8; 32];
        target.to_big_endian(&mut bytes);
        let first_non_zero = bytes.iter().position(|&b| b != 0).unwrap_or(31);
        let mut size = (32 - first_non_zero) as u32;

        let mut mantissa: u32 = if size <= 3 {
            let mut v: u32 = 0;
            for i in first_non_zero..32 {
                v = (v << 8) | bytes[i] as u32;
            }
            v << (8 * (3 - size))
        } else {
            ((bytes[first_non_zero] as u32) << 16)
                | ((bytes[first_non_zero + 1] as u32) << 8)
                | (bytes[first_non_zero + 2] as u32)
        };

        if (mantissa & 0x0080_0000) != 0 {
            mantissa >>= 8;
            size += 1;
        }

        (size << 24) | (mantissa & 0x007f_ffff)
    }

    fn hash_to_u256(hash_hex: &str) -> Result<U256> {
        let normalized = hash_hex.strip_prefix("0x").unwrap_or(hash_hex);
        let bytes = hex::decode(normalized)?;
        if bytes.len() != 32 {
            return Err(anyhow!(
                "invalid hash length for PoW comparison: expected 32 bytes, got {}",
                bytes.len()
            ));
        }
        Ok(U256::from_big_endian(&bytes))
    }

    fn pow_limit_target() -> U256 {
        Self::compact_to_target(Self::POW_LIMIT_BITS)
    }

    fn min_target() -> U256 {
        Self::compact_to_target(Self::POW_MIN_BITS)
    }

    fn is_valid_pow(hash_hex: &str, bits: u32) -> Result<bool> {
        let hash = Self::hash_to_u256(hash_hex)?;
        let target = Self::compact_to_target(bits);
        if target.is_zero() {
            return Ok(false);
        }
        Ok(hash < target)
    }

    pub fn new(db_path: &str) -> Result<Self> {
        let db = open_db(db_path)?;
        // load tip if exists
        let tip = db.get(b"tip")?;
        let chain_tip = tip.map(|v| String::from_utf8(v).unwrap());

        // Load current difficulty from chain tip
        let difficulty = if let Some(ref tip_hash) = chain_tip {
            // Try to load the tip block header
            if let Ok(Some(blob)) = db.get(format!("b:{}", tip_hash).as_bytes()) {
                if let Ok((block, _)) =
                    bincode::decode_from_slice::<Block, _>(&blob, *BINCODE_CONFIG)
                {
                    block.header.difficulty
                } else {
                    log::warn!("Failed to decode tip block, using default difficulty");
                    Self::POW_LIMIT_BITS
                }
            } else {
                log::warn!("Tip block not found, using default difficulty");
                Self::POW_LIMIT_BITS
            }
        } else {
            // No chain exists yet, use default
            Self::POW_LIMIT_BITS
        };

        log::info!("Blockchain initialized with difficulty: {}", difficulty);

        Ok(Blockchain {
            db,
            chain_tip,
            difficulty,
            block_interval: 120,            // Target: 2 minutes per block
            max_reorg_depth: 100, // Maximum 100 blocks deep reorganization (security limit)
            max_future_block_time: 7200, // Max 2 hours in the future (clock drift tolerance)
            enable_deep_reorg_alerts: true, // Alert on suspicious reorgs
        })
    }

    /// Helper: Iterate over all blocks efficiently
    fn get_all_blocks_cached(&self) -> Result<Vec<Block>> {
        // This could be further optimized with caching in production
        self.get_all_blocks()
    }

    /// Create genesis block (with a single coinbase transaction)
    pub fn create_genesis(&mut self, address: &str) -> Result<String> {
        if self.chain_tip.is_some() {
            return Err(anyhow!("chain already exists"));
        }
        let cb = Transaction::coinbase(address, U256::from(50));

        let merkle = compute_merkle_root(&vec![cb.txid.clone()]);
        let header = BlockHeader {
            index: 0,
            previous_hash: "0".repeat(64),
            merkle_root: merkle,
            timestamp: Utc::now().timestamp(),
            nonce: 0,
            difficulty: self.difficulty,
        };
        let hash = compute_header_hash(&header)?;
        let block = Block {
            header,
            transactions: vec![cb.clone()],
            hash: hash.clone(),
        };

        // commit atomically
        let mut batch = WriteBatch::default();
        // Store complete block (header + transactions)
        let block_blob = bincode::encode_to_vec(&block, *BINCODE_CONFIG)?;
        batch.put(format!("b:{}", hash).as_bytes(), &block_blob);
        // tx
        let tx_blob = bincode::encode_to_vec(&cb, *BINCODE_CONFIG)?;
        batch.put(format!("t:{}", cb.txid).as_bytes(), &tx_blob);

        for (i, out) in cb.outputs.iter().enumerate() {
            let utxo = Utxo::new(cb.txid.clone(), i as u32, out.to.clone(), out.amount());

            let utxo_blob = bincode::encode_to_vec(&utxo, *BINCODE_CONFIG)?;
            batch.put(format!("u:{}:{}", cb.txid, i).as_bytes(), &utxo_blob);
        }

        // index
        batch.put(format!("i:0").as_bytes(), hash.as_bytes());
        batch.put(b"tip", hash.as_bytes());

        put_batch(&self.db, batch)?;
        self.chain_tip = Some(hash.clone());
        Ok(hash)
    }

    /// validate and insert block (core of migration/consensus)
    pub fn validate_and_insert_block(&mut self, block: &Block) -> Result<()> {
        // 1) header hash match
        let computed = compute_header_hash(&block.header)?;
        if computed != block.hash {
            crate::security::VALIDATION_STATS
                .increment(crate::security::BlockFailureReason::HashMismatch);
            log::warn!(
                "ðŸš« Block validation failed [hash_mismatch]: height={} computed={} actual={}",
                block.header.index,
                &computed[..16],
                &block.hash[..16]
            );
            return Err(anyhow!(
                "header hash mismatch: computed {} != block.hash {}",
                computed,
                block.hash
            ));
        }

        // 2) Proof-of-Work: verify hash is below target (Bitcoin-style)
        if !Self::is_valid_pow(&block.hash, block.header.difficulty)? {
            crate::security::VALIDATION_STATS
                .increment(crate::security::BlockFailureReason::InvalidPoW);
            let target = Self::compact_to_target(block.header.difficulty);
            log::warn!(
                "ðŸš« Block validation failed [invalid_pow]: height={} hash={} bits=0x{:08x}",
                block.header.index,
                &block.hash[..16],
                block.header.difficulty
            );
            return Err(anyhow!(
                "invalid PoW: hash {} is not below target {} (bits=0x{:08x})",
                block.hash,
                target,
                block.header.difficulty
            ));
        }

        // 3) Difficulty check: verify block difficulty is within reasonable range
        // During sync, we accept the block's difficulty if it meets PoW requirements
        // The difficulty in the header represents what was required when the block was mined
        // We validate that the PoW (checked above) matches the claimed difficulty
        // For additional safety, ensure difficulty doesn't regress too much
        if block.header.index > 0 {
            // Load previous block to check difficulty progression
            let prev_key = format!("b:{}", block.header.previous_hash);
            if let Ok(Some(prev_bytes)) = self.db.get(prev_key.as_bytes()) {
                if let Ok((prev_header, _)) =
                    bincode::decode_from_slice::<BlockHeader, _>(&prev_bytes, *BINCODE_CONFIG)
                {
                    let prev_target = Self::compact_to_target(prev_header.difficulty);
                    let current_target = Self::compact_to_target(block.header.difficulty);

                    // Allow target to change by at most 4x per block in either direction.
                    // (Equivalent to Bitcoin-style retarget clamping safety)
                    if current_target.is_zero()
                        || (!prev_target.is_zero()
                            && ((current_target > prev_target
                                && (current_target / prev_target) > U256::from(4u8))
                                || (current_target < prev_target
                                    && (prev_target / current_target) > U256::from(4u8))))
                    {
                        crate::security::VALIDATION_STATS
                            .increment(crate::security::BlockFailureReason::DifficultyOutOfRange);
                        log::warn!(
                            "ðŸš« Block validation failed [difficulty_out_of_range]: height={} got_bits=0x{:08x} prev_bits=0x{:08x}",
                            block.header.index,
                            block.header.difficulty,
                            prev_header.difficulty
                        );
                        return Err(anyhow!(
                            "difficulty target changed too aggressively at block {}: got bits=0x{:08x}, previous bits=0x{:08x}",
                            block.header.index,
                            block.header.difficulty,
                            prev_header.difficulty
                        ));
                    }
                }
            }
        }

        // 4) merkle check
        let txids: Vec<String> = block.transactions.iter().map(|t| t.txid.clone()).collect();
        let merkle = compute_merkle_root(&txids);
        if merkle != block.header.merkle_root {
            crate::security::VALIDATION_STATS
                .increment(crate::security::BlockFailureReason::MerkleRootMismatch);
            log::warn!(
                "ðŸš« Block validation failed [merkle_mismatch]: height={} computed={} header={}",
                block.header.index,
                merkle,
                block.header.merkle_root
            );
            return Err(anyhow!("merkle mismatch"));
        }

        // 4.5) Median-Time-Past validation (prevent timestamp manipulation)
        if block.header.index > 0 {
            self.validate_median_time_past(block)?;
        }

        // 5) previous exists (unless genesis)
        if block.header.index > 0 {
            let prev_key = format!("b:{}", block.header.previous_hash);
            if self.db.get(prev_key.as_bytes())?.is_none() {
                crate::security::VALIDATION_STATS
                    .increment(crate::security::BlockFailureReason::PreviousNotFound);
                log::warn!(
                    "ðŸš« Block validation failed [previous_not_found]: height={} prev_hash={}",
                    block.header.index,
                    &block.header.previous_hash[..16]
                );
                return Err(anyhow!(
                    "previous header not found: {}",
                    block.header.previous_hash
                ));
            }
        }

        // 6) transactions validation: signatures + UTXO references
        // We'll create a WriteBatch and atomically apply changes
        let mut batch = WriteBatch::default();

        // ðŸ”’ Security: Validate block-level constraints
        crate::security::validate_block_security(&block)?;

        // ðŸ”’ Policy: Check against checkpoint policy (not consensus, but node policy)
        if !crate::checkpoint::validate_against_checkpoints(block.header.index, &block.hash) {
            log::warn!(
                "Block {} at height {} conflicts with checkpoint policy - rejecting",
                &block.hash[..16],
                block.header.index
            );
            return Err(anyhow!(
                "Block violates checkpoint policy at height {}",
                block.header.index
            ));
        }

        // For coinbase check
        if block.transactions.is_empty() {
            return Err(anyhow!("empty block"));
        }

        // coinbase must be first tx and inputs empty
        let coinbase = &block.transactions[0];
        if !coinbase.inputs.is_empty() {
            return Err(anyhow!("coinbase must have no inputs"));
        }

        // iterate non-coinbase txs
        for (i, tx) in block.transactions.iter().enumerate() {
            // ðŸ”’ Security: Validate transaction-level constraints
            crate::security::validate_transaction_security(tx, block.header.timestamp)?;

            // verify signature(s)
            if !tx.verify_signatures()? {
                return Err(anyhow!("tx signature invalid: {}", tx.txid));
            }

            // coinbase skip UTXO referencing checks
            if i == 0 {
                // persist tx and utxos
                let tx_blob = bincode::encode_to_vec(tx, *BINCODE_CONFIG)?;
                batch.put(format!("t:{}", tx.txid).as_bytes(), &tx_blob);
                for (v, out) in tx.outputs.iter().enumerate() {
                    // Normalize address to lowercase for consistent storage
                    let normalized_address = out.to.to_lowercase();
                    let utxo =
                        Utxo::new(tx.txid.clone(), v as u32, normalized_address, out.amount());
                    let ublob = bincode::encode_to_vec(&utxo, *BINCODE_CONFIG)?;
                    batch.put(format!("u:{}:{}", tx.txid, v).as_bytes(), &ublob);
                }
                continue;
            }

            // for non-coinbase tx, check each input exists in UTXO and sum amounts
            let mut input_sum = U256::zero();
            let mut used_utxos = std::collections::HashSet::new();

            for inp in &tx.inputs {
                let ukey = format!("u:{}:{}", inp.txid, inp.vout);

                // ðŸ”’ Security: Prevent double-spending within same transaction
                if !used_utxos.insert(ukey.clone()) {
                    return Err(anyhow!(
                        "duplicate input in tx {}: {}:{}",
                        tx.txid,
                        inp.txid,
                        inp.vout
                    ));
                }

                match self.db.get(ukey.as_bytes())? {
                    Some(blob) => {
                        let (u, _): (Utxo, usize) =
                            bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;

                        // ðŸ”’ Security: CRITICAL - Verify UTXO ownership
                        // Derive address from input's public key and compare with UTXO owner
                        let input_address = crate::crypto::eth_address_from_pubkey_hex(&inp.pubkey)
                            .map_err(|e| anyhow!("invalid pubkey in input: {}", e))?;

                        let utxo_owner = u.to.to_lowercase();
                        let input_addr_lower = input_address.to_lowercase();

                        if input_addr_lower != utxo_owner {
                            return Err(anyhow!(
                                "UTXO ownership verification failed for {}:{} - expected {}, got {}",
                                inp.txid,
                                inp.vout,
                                utxo_owner,
                                input_addr_lower
                            ));
                        }

                        input_sum = input_sum + u.amount();
                        // mark as spent by deleting in batch
                        batch.delete(ukey.as_bytes());
                    }
                    None => {
                        return Err(anyhow!(
                            "referenced utxo not found {}:{} (already spent or never existed)",
                            inp.txid,
                            inp.vout
                        ));
                    }
                }
            }

            let mut output_sum = U256::zero();
            for out in &tx.outputs {
                output_sum = output_sum + out.amount();
            }

            // ðŸ”’ Security: Validate fee is reasonable (outputs <= inputs)
            if output_sum > input_sum {
                return Err(anyhow!(
                    "invalid transaction {}: outputs ({}) exceed inputs ({})",
                    tx.txid,
                    output_sum,
                    input_sum
                ));
            }

            // ðŸ”’ Security: Enforce minimum fee based on transaction size (prevent DDoS)
            // Uses Anti-DDoS fee policy from config.rs: BASE_MIN_FEE + (size Ã— rate)
            let fee = input_sum - output_sum;
            let tx_blob = bincode::encode_to_vec(tx, *BINCODE_CONFIG)?;
            let min_fee = crate::config::calculate_min_fee(tx_blob.len());

            if fee < min_fee {
                return Err(anyhow!(
                    "transaction fee too low {}: got {} ram, need {} ram (base 100 Twei + {} bytes Ã— 200 Gwei/byte)",
                    tx.txid,
                    fee,
                    min_fee,
                    tx_blob.len()
                ));
            }

            // persist tx and create new utxos
            let tx_blob = bincode::encode_to_vec(tx, *BINCODE_CONFIG)?;
            batch.put(format!("t:{}", tx.txid).as_bytes(), &tx_blob);
            for (v, out) in tx.outputs.iter().enumerate() {
                // Normalize address to lowercase for consistent storage
                let normalized_address = out.to.to_lowercase();
                let utxo = Utxo::new(tx.txid.clone(), v as u32, normalized_address, out.amount());
                let ublob = bincode::encode_to_vec(&utxo, *BINCODE_CONFIG)?;
                batch.put(format!("u:{}:{}", tx.txid, v).as_bytes(), &ublob);
            }
        }

        // persist complete block, index, tip
        let block_blob = bincode::encode_to_vec(&block, *BINCODE_CONFIG)?;
        batch.put(format!("b:{}", block.hash).as_bytes(), &block_blob);
        batch.put(
            format!("i:{}", block.header.index).as_bytes(),
            block.hash.as_bytes(),
        );
        batch.put(b"tip", block.hash.as_bytes());

        // commit
        put_batch(&self.db, batch)?;
        self.chain_tip = Some(block.hash.clone());

        // Adjust difficulty every 30 blocks
        let next_index = block.header.index + 1;
        if let Ok(new_difficulty) = self.calculate_adjusted_difficulty(next_index) {
            if new_difficulty != self.difficulty {
                log::info!(
                    "Difficulty updated for next block ({}): {} -> {}",
                    next_index,
                    self.difficulty,
                    new_difficulty
                );
                // Update in-memory difficulty for next mining round
                self.difficulty = new_difficulty;
            }
        }

        Ok(())
    }

    /// helper: load block header by hash
    pub fn load_header(&self, hash: &str) -> Result<Option<BlockHeader>> {
        if let Some(blob) = self.db.get(format!("b:{}", hash).as_bytes())? {
            let (block, _): (Block, usize) = bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;
            return Ok(Some(block.header));
        }
        Ok(None)
    }

    /// load tx by id
    pub fn load_tx(&self, txid: &str) -> Result<Option<Transaction>> {
        if let Some(blob) = self.db.get(format!("t:{}", txid).as_bytes())? {
            let (t, _): (Transaction, usize) = bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;
            return Ok(Some(t));
        }
        Ok(None)
    }

    /// get balance by scanning UTXO set (use get_address_balance_from_db instead)
    #[deprecated(note = "Use get_address_balance_from_db instead")]
    pub fn get_balance(&self, address: &str) -> Result<U256, Box<dyn std::error::Error>> {
        Ok(self.get_address_balance_from_db(address)?)
    }

    /// Determine next block index based on current tip
    pub fn get_next_index(&self) -> Result<u64> {
        if let Some(ref tip_hash) = self.chain_tip {
            if let Some(prev) = self.load_header(tip_hash)? {
                // assume BlockHeader.index is u64 or can be cast; adjust if different
                return Ok(prev.index + 1);
            }
        }
        Ok(0)
    }

    /// Validate Median-Time-Past (MTP) - block timestamp must be greater than median of last 11 blocks
    /// This prevents miners from lying about timestamps to manipulate difficulty
    fn validate_median_time_past(&self, block: &Block) -> Result<()> {
        const MTP_SPAN: usize = 11; // Bitcoin uses 11 blocks

        let mut timestamps = Vec::new();
        let mut current_hash = block.header.previous_hash.clone();

        // Collect up to 11 previous block timestamps
        for _ in 0..MTP_SPAN {
            if let Some(blk) = self.load_block(&current_hash)? {
                timestamps.push(blk.header.timestamp);
                if blk.header.index == 0 {
                    break; // Reached genesis
                }
                current_hash = blk.header.previous_hash.clone();
            } else {
                break;
            }
        }

        if timestamps.is_empty() {
            // No previous blocks, skip MTP check
            return Ok(());
        }

        // Calculate median
        timestamps.sort_unstable();
        let median = if timestamps.len() % 2 == 0 {
            (timestamps[timestamps.len() / 2 - 1] + timestamps[timestamps.len() / 2]) / 2
        } else {
            timestamps[timestamps.len() / 2]
        };

        // Block timestamp must be strictly greater than MTP
        if block.header.timestamp <= median {
            return Err(anyhow!(
                "Block timestamp {} violates Median-Time-Past {} (must be > MTP)",
                block.header.timestamp,
                median
            ));
        }

        Ok(())
    }

    /// Calculate adjusted difficulty based on recent block times
    /// Adjustment period: every block (using rolling 30-block window)
    /// Target: 120 seconds per block (2 minutes)
    /// Bitcoin-style: U256 hash target retargeting with damped updates
    pub fn calculate_adjusted_difficulty(&self, current_index: u64) -> Result<u32> {
        // No adjustment until enough history is available
        if current_index < Self::RETARGET_WINDOW {
            return Ok(self.difficulty);
        }

        // Rolling window: compare timestamps of [current_index - window, current_index - 1]
        let start_index = current_index - Self::RETARGET_WINDOW;
        let start_hash = self.db.get(format!("i:{}", start_index).as_bytes())?;
        let end_hash = self.db.get(format!("i:{}", current_index - 1).as_bytes())?;

        if start_hash.is_none() || end_hash.is_none() {
            log::warn!("Cannot find blocks for difficulty adjustment");
            return Ok(self.difficulty);
        }

        let start_hash_str = String::from_utf8(start_hash.unwrap())?;
        let end_hash_str = String::from_utf8(end_hash.unwrap())?;

        let start_header = self.load_header(&start_hash_str)?;
        let end_header = self.load_header(&end_hash_str)?;

        if start_header.is_none() || end_header.is_none() {
            log::warn!("Cannot load headers for difficulty adjustment");
            return Ok(self.difficulty);
        }

        let start_time = start_header.unwrap().timestamp;
        let end_time = end_header.unwrap().timestamp;

        // Calculate actual time taken for the last window
        let raw_actual_time = (end_time - start_time).max(1);
        let target_time = self.block_interval * Self::RETARGET_WINDOW as i64;
        let clamped_actual_time = raw_actual_time.clamp(target_time / 4, target_time * 4);

        log::info!(
            "Difficulty adjustment at block {}: actual={}s, target={}s, avg={:.1}s/block",
            current_index,
            raw_actual_time,
            target_time,
            raw_actual_time as f64 / Self::RETARGET_WINDOW as f64
        );

        let ratio = raw_actual_time as f64 / target_time as f64;

        let current_difficulty = self.difficulty;
        let pow_limit = Self::pow_limit_target();
        let min_target = Self::min_target();
        let current_target = {
            let t = Self::compact_to_target(current_difficulty);
            if t.is_zero() { pow_limit } else { t }
        };

        // Core Bitcoin-style retarget: new_target = old_target * actual / target
        let mut retargeted = (current_target * U256::from(clamped_actual_time as u64))
            / U256::from(target_time as u64);

        // Clamp target bounds
        if retargeted > pow_limit {
            retargeted = pow_limit;
        }
        if retargeted < min_target {
            retargeted = min_target;
        }

        // Damp oscillations: apply only 25% of the computed move each block.
        let damped = if retargeted > current_target {
            current_target + ((retargeted - current_target) / U256::from(4u8))
        } else if retargeted < current_target {
            current_target - ((current_target - retargeted) / U256::from(4u8))
        } else {
            current_target
        };

        let final_target = damped.clamp(min_target, pow_limit);
        let final_difficulty = Self::target_to_compact(final_target);

        if final_difficulty != current_difficulty {
            log::info!(
                "Difficulty adjusted: bits 0x{:08x} -> 0x{:08x} (ratio: {:.2}x target, avg: {:.1}s/block vs target: {}s/block)",
                current_difficulty,
                final_difficulty,
                ratio,
                raw_actual_time as f64 / Self::RETARGET_WINDOW as f64,
                self.block_interval
            );
        } else {
            log::info!(
                "Difficulty unchanged: bits 0x{:08x} (ratio: {:.2}x, within acceptable range)",
                current_difficulty,
                ratio
            );
        }

        Ok(final_difficulty)
    }

    /// Find a valid nonce by updating header.nonce and computing header hash.
    /// Returns (nonce, hash).
    pub fn find_valid_nonce(
        &self,
        header: &mut BlockHeader,
        difficulty: u32,
    ) -> Result<(u64, String)> {
        let target = Self::compact_to_target(difficulty);
        if target.is_zero() {
            return Err(anyhow!(
                "cannot mine with invalid target bits: 0x{:08x}",
                difficulty
            ));
        }

        let mut nonce: u64 = header.nonce;

        loop {
            header.nonce = nonce;
            let hash = compute_header_hash(header)?;
            let hash_u256 = Self::hash_to_u256(&hash)?;
            if hash_u256 < target {
                return Ok((nonce, hash));
            }

            nonce = nonce.wrapping_add(1);
            // Periodic yield can be added by caller if needed (to avoid busy-wait in single-threaded contexts)
            // For large scale mining, this loop would be replaced with GPU/parallel miners.
        }
    }

    pub fn get_utxos(&self, address: &str) -> Result<Vec<Utxo>> {
        let mut utxos = Vec::new();
        let iter = self.db.iterator(rocksdb::IteratorMode::Start);

        for item in iter {
            let (key, value) = item?;
            let key_str = String::from_utf8_lossy(&key);

            // UTXO key: u:{txid}:{vout}
            if key_str.starts_with("u:") {
                let (utxo, _): (Utxo, usize) = bincode::decode_from_slice(&value, *BINCODE_CONFIG)?;
                if utxo.to == address {
                    utxos.push(utxo);
                }
            }
        }

        Ok(utxos)
    }

    /// Count transactions stored in DB (keys starting with `t:`)
    pub fn count_transactions(&self) -> Result<usize> {
        let mut count: usize = 0;
        let iter = self.db.iterator(rocksdb::IteratorMode::Start);
        for item in iter {
            let (k, _v) = item?;
            let key_str = String::from_utf8_lossy(&k);
            if key_str.starts_with("t:") {
                count += 1;
            }
        }
        Ok(count)
    }

    /// Load all blocks from DB by iterating through block indices
    pub fn get_all_blocks(&self) -> Result<Vec<Block>> {
        let mut blocks = Vec::new();
        let mut index = 0u64;

        loop {
            let key = format!("i:{}", index);
            match self.db.get(key.as_bytes())? {
                Some(hash_bytes) => {
                    let hash = String::from_utf8(hash_bytes)?;

                    // Load complete block (with transactions) by hash
                    if let Some(blob) = self.db.get(format!("b:{}", hash).as_bytes())? {
                        let (block, _): (Block, usize) =
                            bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;
                        blocks.push(block);
                    }
                    index += 1;
                }
                None => {
                    // No more blocks at this index
                    break;
                }
            }
        }

        Ok(blocks)
    }

    /// Get blocks in a specific height range (inclusive)
    pub fn get_blocks_range(&self, from_height: u64, to_height: Option<u64>) -> Result<Vec<Block>> {
        let mut blocks = Vec::new();
        let mut index = from_height;

        loop {
            // Stop if we've reached the to_height limit
            if let Some(to) = to_height {
                if index > to {
                    break;
                }
            }

            let key = format!("i:{}", index);
            match self.db.get(key.as_bytes())? {
                Some(hash_bytes) => {
                    let hash = String::from_utf8(hash_bytes)?;

                    // Load complete block (with transactions) by hash
                    if let Some(blob) = self.db.get(format!("b:{}", hash).as_bytes())? {
                        let (block, _): (Block, usize) =
                            bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;
                        blocks.push(block);
                    }
                    index += 1;
                }
                None => {
                    // No more blocks at this index
                    break;
                }
            }
        }

        Ok(blocks)
    }

    pub fn get_transaction(&self, txid: &str) -> anyhow::Result<Option<(Transaction, usize)>> {
        let blocks = self.get_all_blocks()?;

        for block in blocks {
            for tx in block.transactions {
                if tx.txid == txid {
                    return Ok(Some((tx, block.header.index as usize)));
                }
            }
        }

        Ok(None)
    }

    /// Get transaction by eth_hash (EVM-compatible hash)
    pub fn get_transaction_by_eth_hash(
        &self,
        eth_hash: &str,
    ) -> anyhow::Result<Option<(Transaction, usize)>> {
        let blocks = self.get_all_blocks()?;

        // Normalize eth_hash (add 0x if missing)
        let normalized_hash = if eth_hash.starts_with("0x") {
            eth_hash.to_string()
        } else {
            format!("0x{}", eth_hash)
        };

        for block in blocks {
            for tx in block.transactions {
                if tx.eth_hash == normalized_hash {
                    return Ok(Some((tx, block.header.index as usize)));
                }
            }
        }

        Ok(None)
    }

    /// Calculate total transaction volume from all outputs in DB (in ram)
    pub fn calculate_total_volume(&self) -> Result<U256> {
        let mut total = U256::zero();
        let iter = self.db.iterator(rocksdb::IteratorMode::Start);

        for item in iter {
            let (k, v) = item?;
            let key_str = String::from_utf8_lossy(&k);

            // Iterate through all transaction outputs: u:{txid}:{vout}
            if key_str.starts_with("u:") {
                let (utxo, _): (Utxo, usize) = bincode::decode_from_slice(&v, *BINCODE_CONFIG)?;
                total = total + utxo.amount();
            }
        }

        Ok(total)
    }

    /// Get address balance (sum of unspent outputs) from DB
    pub fn get_address_balance_from_db(&self, address: &str) -> Result<U256> {
        let mut balance = U256::zero();
        let iter = self.db.iterator(rocksdb::IteratorMode::Start);

        for item in iter {
            let (key, value) = item?;
            let key_str = String::from_utf8_lossy(&key);

            // UTXO key: u:{txid}:{vout}
            if key_str.starts_with("u:") {
                match bincode::decode_from_slice::<Utxo, _>(&value, *BINCODE_CONFIG) {
                    Ok((utxo, _)) => {
                        if utxo.to == address {
                            let amount = utxo.amount();
                            balance = balance + amount;
                        }
                    }
                    Err(e) => {
                        log::warn!("Failed to decode UTXO at {}: {}", key_str, e);
                    }
                }
            }
        }
        Ok(balance)
    }

    /// Get total received amount for address (all outputs to this address)
    pub fn get_address_received_from_db(&self, address: &str) -> Result<U256> {
        let mut total = U256::zero();
        let blocks = self.get_all_blocks_cached()?;

        for block in blocks {
            for tx in block.transactions {
                for output in &tx.outputs {
                    if output.to == address {
                        total = total + output.amount();
                    }
                }
            }
        }

        Ok(total)
    }

    /// Get total sent amount for address (all transaction outputs, excluding coinbase inputs)
    pub fn get_address_sent_from_db(&self, address: &str) -> Result<U256> {
        let mut total = U256::zero();
        let blocks = self.get_all_blocks_cached()?;

        for block in blocks {
            for tx in block.transactions {
                // Skip coinbase transactions (first tx in block)
                if !tx.inputs.is_empty() {
                    // Check if any input comes from this address
                    let is_sender = tx.inputs.iter().any(|input| input.pubkey == address);

                    if is_sender {
                        // Sum all outputs from this transaction
                        for output in &tx.outputs {
                            total = total + output.amount();
                        }
                    }
                }
            }
        }

        Ok(total)
    }

    /// Get transaction count for address
    pub fn get_address_transaction_count_from_db(&self, address: &str) -> Result<usize> {
        let blocks = self.get_all_blocks_cached()?;
        let mut seen_txids = std::collections::HashSet::new();

        for block in blocks {
            for tx in block.transactions {
                // Check if address is involved (sender or receiver)
                let is_receiver = tx.outputs.iter().any(|output| output.to == address);
                let is_sender = tx.inputs.iter().any(|input| input.pubkey == address);

                // Count each unique transaction only once
                if (is_receiver || is_sender) && seen_txids.insert(tx.txid.clone()) {
                    // Counter automatically incremented by HashSet
                }
            }
        }

        Ok(seen_txids.len())
    }

    /// Calculate total chain work (cumulative difficulty) from genesis to given block
    /// Higher difficulty blocks contribute more work
    pub fn calculate_chain_work(&self, block_hash: &str) -> Result<u64> {
        let mut total_work = 0u64;
        let mut current_hash = block_hash.to_string();

        loop {
            let block = self.load_block(&current_hash)?;
            if block.is_none() {
                break;
            }

            let block = block.unwrap();

            // ðŸ”’ Security: Validate difficulty is reasonable (prevent invalid blocks)
            if block.header.difficulty == 0 {
                return Err(anyhow!(
                    "Invalid block with difficulty 0 at height {}",
                    block.header.index
                ));
            }

            if block.header.difficulty > 32 {
                return Err(anyhow!(
                    "Invalid block with excessive difficulty {} at height {}",
                    block.header.difficulty,
                    block.header.index
                ));
            }

            // Each difficulty level represents 16x more work (hexadecimal)
            // Work = 16^difficulty
            // Use checked operations to prevent overflow
            let block_work = match 16u64.checked_pow(block.header.difficulty) {
                Some(work) => work,
                None => {
                    log::warn!(
                        "Work calculation overflow at difficulty {}, using max u64",
                        block.header.difficulty
                    );
                    u64::MAX
                }
            };

            // Saturating add to prevent overflow
            total_work = total_work.saturating_add(block_work);

            if block.header.index == 0 {
                break; // Reached genesis
            }

            current_hash = block.header.previous_hash.clone();
        }

        Ok(total_work)
    }

    /// Get block height (index) for a given block hash
    pub fn get_block_height(&self, block_hash: &str) -> Result<Option<u64>> {
        if let Some(block) = self.load_block(block_hash)? {
            Ok(Some(block.header.index))
        } else {
            Ok(None)
        }
    }

    /// Load complete block by hash
    pub fn load_block(&self, hash: &str) -> Result<Option<Block>> {
        if let Some(blob) = self.db.get(format!("b:{}", hash).as_bytes())? {
            let (block, _): (Block, usize) = bincode::decode_from_slice(&blob, *BINCODE_CONFIG)?;
            return Ok(Some(block));
        }
        Ok(None)
    }

    /// Find common ancestor between two blocks
    fn find_common_ancestor(&self, hash_a: &str, hash_b: &str) -> Result<Option<String>> {
        let mut blocks_a = Vec::new();
        let mut current = hash_a.to_string();

        // Collect all blocks from hash_a to genesis
        while let Some(block) = self.load_block(&current)? {
            blocks_a.push(current.clone());
            if block.header.index == 0 {
                break;
            }
            current = block.header.previous_hash.clone();
        }

        // Walk from hash_b to genesis and find first common block
        let mut current = hash_b.to_string();
        while let Some(block) = self.load_block(&current)? {
            if blocks_a.contains(&current) {
                return Ok(Some(current));
            }
            if block.header.index == 0 {
                break;
            }
            current = block.header.previous_hash.clone();
        }

        Ok(None)
    }

    /// Reorganize chain to new tip if it has more work
    /// Returns true if reorg happened, false if current chain is already best
    pub fn reorganize_if_needed(&mut self, new_block_hash: &str) -> Result<bool> {
        let current_tip = match &self.chain_tip {
            Some(tip) => tip.clone(),
            None => {
                // No current chain, accept any valid block
                return Ok(false);
            }
        };

        // Calculate chain work for both tips
        let current_work = self.calculate_chain_work(&current_tip)?;
        let new_work = self.calculate_chain_work(new_block_hash)?;

        log::info!(
            "Chain work comparison: current={} (hash={}), new={} (hash={})",
            current_work,
            &current_tip[..16],
            new_work,
            &new_block_hash[..16]
        );

        // Keep current chain if it has equal or more work
        if current_work >= new_work {
            log::info!("Current chain has more work, keeping it");
            return Ok(false);
        }

        log::warn!(
            "ðŸ”„ REORGANIZATION NEEDED: new chain has more work ({} vs {})",
            new_work,
            current_work
        );

        // Find common ancestor
        let ancestor = self.find_common_ancestor(&current_tip, new_block_hash)?;
        if ancestor.is_none() {
            return Err(anyhow!("No common ancestor found for reorganization"));
        }

        let ancestor = ancestor.unwrap();
        log::info!("Common ancestor: {}", &ancestor[..16]);

        // ðŸ”’ Security: Check reorganization depth to prevent 51% attacks
        let current_header = self
            .load_header(&current_tip)?
            .ok_or_else(|| anyhow!("Cannot load current tip header"))?;
        let ancestor_header = self
            .load_header(&ancestor)?
            .ok_or_else(|| anyhow!("Cannot load ancestor header"))?;

        let current_height = current_header.index;
        let fork_point_height = ancestor_header.index;
        let reorg_depth = current_height - fork_point_height;

        // ðŸ”’ Security: Validate reorganization depth doesn't exceed consensus limit
        crate::security::validate_reorg_depth(
            current_height,
            fork_point_height,
            self.max_reorg_depth,
        )?;

        // ðŸ”’ Policy: Check if reorg conflicts with checkpoint policy
        let (checkpoint_allowed, checkpoint_reason) =
            crate::checkpoint::check_reorg_against_checkpoints(reorg_depth, current_height);

        if !checkpoint_allowed {
            log::error!(
                "ðŸš¨ Reorganization REJECTED by checkpoint policy: {}",
                checkpoint_reason.unwrap_or_else(|| "Unknown reason".to_string())
            );
            return Err(anyhow!(
                "Reorganization violates checkpoint policy (depth: {}, current height: {})",
                reorg_depth,
                current_height
            ));
        }

        log::info!(
            "âœ… Reorganization passes checkpoint policy check (depth: {}, height: {})",
            reorg_depth,
            current_height
        );

        // Collect blocks to rollback (from current tip to ancestor)
        let mut rollback_blocks = Vec::new();
        let mut current = current_tip.clone();
        while current != ancestor {
            let block = self
                .load_block(&current)?
                .ok_or_else(|| anyhow!("Block not found during reorg: {}", current))?;
            rollback_blocks.push(block.clone());
            current = block.header.previous_hash.clone();
        }

        // Collect blocks to apply (from ancestor to new tip)
        let mut apply_blocks = Vec::new();
        let mut current = new_block_hash.to_string();
        while current != ancestor {
            let block = self
                .load_block(&current)?
                .ok_or_else(|| anyhow!("Block not found during reorg: {}", current))?;
            apply_blocks.push(block.clone());
            current = block.header.previous_hash.clone();
        }
        apply_blocks.reverse(); // Apply from ancestor to new tip

        log::warn!(
            "Reorganizing: rolling back {} blocks, applying {} blocks",
            rollback_blocks.len(),
            apply_blocks.len()
        );

        // Rollback: reverse UTXO changes
        self.rollback_blocks(&rollback_blocks)?;

        // Apply: replay new chain
        self.replay_blocks(&apply_blocks)?;

        // Update chain tip
        let mut batch = WriteBatch::default();
        batch.put(b"tip", new_block_hash.as_bytes());
        put_batch(&self.db, batch)?;
        self.chain_tip = Some(new_block_hash.to_string());

        log::warn!(
            "âœ… Reorganization complete: new tip = {}",
            &new_block_hash[..16]
        );

        Ok(true)
    }

    /// Rollback UTXO changes from a list of blocks (reverse order)
    fn rollback_blocks(&mut self, blocks: &[Block]) -> Result<()> {
        let mut batch = WriteBatch::default();

        for block in blocks {
            log::info!("Rolling back block {}", block.header.index);

            // Process transactions in reverse order
            for tx in block.transactions.iter().rev() {
                // Delete UTXOs created by this transaction
                for i in 0..tx.outputs.len() {
                    let ukey = format!("u:{}:{}", tx.txid, i);
                    batch.delete(ukey.as_bytes());
                }

                // Restore UTXOs spent by this transaction (skip coinbase)
                if !tx.inputs.is_empty() {
                    for input in &tx.inputs {
                        // Restore the UTXO that was spent
                        let spent_tx = self
                            .load_tx(&input.txid)?
                            .ok_or_else(|| anyhow!("Cannot find spent tx: {}", input.txid))?;

                        if let Some(output) = spent_tx.outputs.get(input.vout as usize) {
                            let utxo = Utxo::new(
                                input.txid.clone(),
                                input.vout,
                                output.to.clone(),
                                output.amount(),
                            );
                            let ublob = bincode::encode_to_vec(&utxo, *BINCODE_CONFIG)?;
                            batch.put(
                                format!("u:{}:{}", input.txid, input.vout).as_bytes(),
                                &ublob,
                            );
                        }
                    }
                }
            }
        }

        put_batch(&self.db, batch)?;
        Ok(())
    }

    /// Replay blocks to apply UTXO changes (forward order)
    fn replay_blocks(&mut self, blocks: &[Block]) -> Result<()> {
        for block in blocks {
            log::info!("Replaying block {}", block.header.index);

            // We already have the block stored, just need to update UTXO set
            let mut batch = WriteBatch::default();

            for tx in &block.transactions {
                // Create new UTXOs
                for (i, output) in tx.outputs.iter().enumerate() {
                    let utxo = Utxo::new(
                        tx.txid.clone(),
                        i as u32,
                        output.to.clone(),
                        output.amount(),
                    );
                    let ublob = bincode::encode_to_vec(&utxo, *BINCODE_CONFIG)?;
                    batch.put(format!("u:{}:{}", tx.txid, i).as_bytes(), &ublob);
                }

                // Spend UTXOs (skip coinbase)
                if !tx.inputs.is_empty() {
                    for input in &tx.inputs {
                        batch.delete(format!("u:{}:{}", input.txid, input.vout).as_bytes());
                    }
                }
            }

            put_batch(&self.db, batch)?;
        }

        Ok(())
    }
}
